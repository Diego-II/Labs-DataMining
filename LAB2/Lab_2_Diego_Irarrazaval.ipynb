{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Laboratorio N 2 </h1\n",
    "\n",
    "Integrantes:\n",
    "\n",
    "    1. Diego Irarrazaval\n",
    "\n",
    "\n",
    "El formato de entrega será subir a u-cursos **un Jupyter notebook\n",
    "Lab_2_apellido_nombre.ipynb por grupo**, donde el nombre y apellido de algun integrante del grupo.\n",
    "El jupyter debe ejecutarse de manera continua sin errores. Todo el código debe estar en el mismo notebook.\n",
    "\n",
    "<h2> Instrucciones </h2>\n",
    "El laboratorio consta de 4 partes y un total de 6 puntos, donde la nota final es el puntaje más un punto base.\n",
    "\n",
    "La asignación de puntaje es la siguiente:\n",
    "\n",
    "    1.  Preguntas conceptuales          1 pto.\n",
    "\n",
    "    2.  Limpieza de datos.              3 ptos.\n",
    "\n",
    "    3.  Transformación de variables.    1 pto.\n",
    "    \n",
    "    4.  Selección de atributos.         1 pto.  \n",
    "\n",
    "\n",
    "<h2> Preguntas conceptuales </h2>\n",
    "\n",
    "0.5 pts cada una.\n",
    "<h5> Pregunta 1 </h5>\n",
    "\n",
    "    1.1. Su grupo está calibrando un modelo de clasificación de fraude para la asignación de un beneficio del gobierno.\n",
    "    \n",
    "     El objetivo de su equipo es poder detectar que aplicaciones al beneficio fueron realizadas por ciudadanos quienes no calificaban para obtener el benedicio, por ende solicitaron el beneficio sin reportar los valores reales para obtener el beneficio.\n",
    "\n",
    "        Un proceso de auditoria por un organismo externo determinó que solicitantes del beneficio para la última entrega fueron entregados a personas que en realidad no calificaban para el beneficio, por lo que tienen los datos para poder armar y entrenar su modelo.\n",
    "\n",
    "        Al armar su modelo se encuentra con los siguientes problemas que va resolviendo según están mencionados:\n",
    "\n",
    "                1.  Su modelo le entrega un error, ya que el paquete solo permite variables de tipo float.\n",
    "\n",
    "                    Soluciona el problema, luego \n",
    "\n",
    "                2.  Logra entrenar su modelo pero el coeficiente de una de sus variables captura la mayoria del poder explicativo de su modelo. Usted sabe que las demás variables también son determinantes en definir el comportamiento de fraude, sin embargo al probar distintas opciones de la función que está usando sigue obteniendo el cooeficiente de esa variable con un valor mucho más grande con respecto al coeficiente de las demás variables.\n",
    "\n",
    "                    Soluciona el problema, luego\n",
    "\n",
    "                3. Logra entrenar su modelo con un mayor grado de precisión ya que arregló el problema anterior, sin embargo, al presentar su resultado al comité evaluador que le pidió que armara el modelo le preguntan por qué el coeficiente de una de sus variables es tan pequeño en relación a las expectativas del comité, ya que para el comité esa variable debería tener mayor relevancia. \n",
    "                    En particular les llama la atención que al estudiar la variable determinó que la varianza de la variable es mucho más alta de lo esperada y prácticamente es casi de la magnitud del rango factible de la variable.\n",
    "\n",
    "                    Soluciona el problema y el comité evaluador queda satisfecho con los resultados.\n",
    "\n",
    "        Comente a juicio de su grupo, que problemas se enfrentó al desarollar el modelo, por qué esto es un problema y cómo lo solucionó el equipo que presentó el modelo.\n",
    "        \n",
    "<h5> Pregunta 1.2 </h5>\n",
    "\n",
    "    1.2.  Una importante consultora del rubro público dentro de sus estudios un informe sobre el desempeño regional sobre la respuesta de cada país frente a la actual pandemia COVID-19. \n",
    "        Una organización extranjera se pone en contacto con el grupo para presentar una versión de la verdad \"alternativa\", el objetivo de la organización es presentar el resultado frente a la respuesta de manera favorable para fortalezer la posición de un candidato a disputar la elección que se realizará en el país dentro del futuro cercano.\n",
    "\n",
    "\n",
    "    A pesar de que le enseñaron a actuar de manera ética en su formación decide ayudar a la organización a presentar de manera favorable el resultado en el país. Sin embargo, su conciencia le impide inventar datos ya que sería muy fácil de detectar además de tener un dilema ético.\n",
    "\n",
    "\n",
    "    Sabe que las localidades de menos recursos dentro del país decidieron diagnosticar el COVID mediante imágenes de rayos-x en lugar de hacer un test de laboratorio como se hizo en el resto del país. La preparación de los centros de salud en estas localidades fue escasa y por ende resultó en una tasa de fatalidad mucho mayor a la del resto del país.\n",
    "\n",
    "\n",
    "    Al registrar y reportar los datos estas localidades decidieron no clasificarlos como pacientes covid sino que una variable adicional <i> enfermedad pulmonar pandemica por imagenes </i>, al ser localidades remotas estas no representan la mayoría de los casos, sin embargo los resultados son muy malos comparados con el resto del país.\n",
    "\n",
    "\n",
    "    Determine que acción va a realizar con los datos para poder presentar el actuar del organismo de salud de manera más favorable respetando el deseo de su conciencia donde no puede reemplazar información existente por valores falsos.\n",
    "\n",
    "\n",
    "\n",
    "    Explique por qué esta acción no es una representación honesta de los datos y que argumentos debería ocupar la oposición del país donde está haciendo su trabajo, para establecer una versión más cercana a la realidad frente a la opinión pública."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respuestas preguntas conceptuales:\n",
    "#### P1.1\n",
    "En primer lugar, sobre el tipo de datos aceptado es probable que haya habido variables del tipo `str` u otras no numericas que afectaran y arrojaran ese error. Es importante al codificar, mantener el arreglo que permita 'decodificar'. \n",
    "\n",
    "Sobre los coeficientes que se esperaba que fueran mas o menos importantes, se puede deber a que el rango de las variables es muy grande o son ordenes de magnitud mas grandes que otras. Lo mismo con la variable de la que se esperaba mas. Para esto, se pueden realizar transformaciones antes de aplicar el modelo. Por ejemplo, MinMaxScaler, o normalizar son ejemplos de transformaciones comunes. Otra puede ser aplicar el logaritmo de una variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P1.2 \n",
    "Una forma de que los numeros sean mas favorablles, seria aplicar un promedio ponderado con eficiencia de respuesta. De esta forma, estas localidades remotas afectaran muy levemente el promedio y las comunidades con mayor poblacion (donde, en teoria se respondio mejor), afectaran mas al promedio dejandolo 'mas bonito'. \n",
    "\n",
    "De esa forma, no se inventaron datos ni se ocultaron. Otra forma, podria ser normalizar o estandarizar los datos. \n",
    "\n",
    "Esto, no es una representacion 100% honesta porque para ver realmente el desempeno de las autoridades frente al COVID-19, es importante estudiar los datos de forma des-agregada, es decir a nivel local. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Pregunta 1.2 </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfo = pd.read_csv('https://raw.githubusercontent.com/saguerraty/Aux-IN6531-/master/Laboratorio_2/sfo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfo.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Pregunta 2 </h3>\n",
    "\n",
    "(3 pts)\n",
    "\n",
    "Para esta pregunta debe utilizar la tabla <i> sfo </i> cargada anteriormente\n",
    "\n",
    "    1.  Determine que columnas tienen datos faltantes y cuantos datos faltantes tienen (0.2 pts)\n",
    "\n",
    "    2.  Impute dos variables por algún valor fijo que le pareza dentro del rango de la variable. \n",
    "    \n",
    "        Muestre la distribución de la variable antes y después de reemplazar los datos faltantes para ambas variables. Comente si debería mantener esta imputación sobre sus datos faltantes justificando el motivo. ( 0.3 pts)\n",
    "\n",
    "    3.  Use algún método con variabilidad sobre los datos imputados para estimar el valor de los datos faltantes de la variable <i> Revised cost </i>, compare el promedio y la distribución de la variable sin considerar los datos faltantes y luego de imputar los datos con variabilidad. Para usar datos de manera agregada (resumida) le parece razonable su metodo de imputación? justificando su respuesta. (1 pto.)\n",
    "\n",
    "Para las siguientes preguntas elimine las filas que tienen un valor faltante para la columna <i> permit slack </i>\n",
    "\n",
    "    4. Determine que variables no debería considerar de los datos de sfo, justifique su respuesta y elimine las variables del de la tabla. (0.5 pts)\n",
    "\n",
    "    5.  Use algún método predictivo para estimar los datos faltantes de las variables que no consideró eliminar en la parte anterior. (1.5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Conteo de datos faltantes por columna. Las columnas con 0 no tienen datos faltantes.\n",
    "sfo.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se reemplazaran los datos faltantes en las columnas `existing units` y `existing construction type`. Para esto, simplemente se rellenara con `0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se creara una copia para no modificar el dataset original.\n",
    "fill_dict = {'Existing Units':0, 'Existing Construction Type': 0}\n",
    "sfo_zero_filled = sfo.fillna(fill_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos que rellenamos los NAN en sfo_zero_filled:\n",
    "sfo_zero_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafiquemos las distribuciones antes y despues\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.distplot(sfo['Existing Units'], label = \"Distribucion original\", kde = False)\n",
    "sns.distplot(sfo_zero_filled['Existing Units'], label = \"Nueva distribucion\", kde = False)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(sfo['Existing Construction Type'], label = \"Distribucion original\", kde = False)\n",
    "sns.distplot(sfo_zero_filled['Existing Construction Type'], label = \"Nueva distribucion\", kde = False)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P2.2, comentarios:\n",
    "En la variable `'Existing Units'`, no hay cambios significativos en la distribucion de los datos. En ambos casos hay gran concentracion cerca de cero y la distribucion de las colas obviamente no cambia al rellenar con ceros. \n",
    "\n",
    "Por otro lado, en `'Existing Construction Type'` se agrega una categoria que antes no existia. Se puede decir que la clase `0` correspondiente a los `null` es inventar informacion. Esta transformacion, si el modelo final depende de esta variable (o se intenta predecir esta variable), no se debe mantener. Para efectos de visualizacion no habra problemas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P2.3\n",
    "Use algún método con variabilidad sobre los datos imputados para estimar el valor de los datos faltantes de la variable `'Revised cost'`, compare el promedio y la distribución de la variable sin considerar los datos faltantes y luego de imputar los datos con variabilidad. Para usar datos de manera agregada (resumida) le parece razonable su metodo de imputación? justificando su respuesta. (1 pto.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cantidad de filas con 'Revised Cost' vacia (o NaN) = \", sfo['Revised Cost'].isna().sum())\n",
    "print(\"Distribucion original de variable 'Revised Cost'\")\n",
    "sns.distplot(sfo['Revised Cost'])\n",
    "sfo[['Revised Cost']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenemos con valores aleatorios extraidos dde la columna 'Revised Cost.'\n",
    "import numpy as np\n",
    "sfo_random_filled = sfo.copy()\n",
    "column = 'Revised Cost'\n",
    "sfo_random_filled[column] = sfo_random_filled[column].apply(lambda x: np.random.choice(sfo_random_filled[column].dropna().values) if np.isnan(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobemos la distribucion original vs la nueva:\n",
    "print(\"Cantidad de filas con 'Revised Cost' vacia (o NaN) = \", sfo_random_filled['Revised Cost'].isna().sum())\n",
    "print(\"Distribucion final de variable 'Revised Cost'\")\n",
    "sns.distplot(sfo_random_filled['Revised Cost'])\n",
    "sfo_random_filled[['Revised Cost']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el promedio y la desviacion varian pero graficamente no hay una variacion considerable en la distribucion. Es importante comentar que, los valores de `'Revised Cost'` tienen un rango grande con una desviacion estandar grande tambien. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Pregunta 3 <h3>\n",
    "\n",
    "(1 pto)\n",
    "\n",
    "Quiere agregar segmentación a su análisis para poder usar características comunes dentro de un grupo como entrada para un modelo predictivo con la tabla.\n",
    "\n",
    "Modifique la versión que tiene con los datos imputados para no sobre estimar alguna variable en su segmentación. Justifique sus cambios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta seccion, se normalizan usando `MinMaxScaler` del modulo `sklearn.preprocessing`. Se aplica sobre las columnas `['Revised Cost', 'Estimated Cost']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos un dataframe con los NaN anteriormente tratados:\n",
    "fill_dict = {'Existing Units':0, 'Existing Construction Type': 0}\n",
    "sfo_filled = sfo.fillna(fill_dict)\n",
    "\n",
    "column = 'Revised Cost'\n",
    "sfo_filled[column] = sfo_filled[column].apply(lambda x: np.random.choice(sfo_filled[column].dropna().values) if np.isnan(x) else x)\n",
    "# Se normalizaran algunas columas:\n",
    "columnas_a_normalizar = ['Revised Cost', 'Estimated Cost']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "sfo_norm = sfo_filled.copy()\n",
    "\n",
    "sfo_norm[columnas_a_normalizar] = scaler.fit_transform(sfo_norm[columnas_a_normalizar])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfo_norm[columnas_a_normalizar].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Pregunta 4 </h3>\n",
    "\n",
    "(1 pto)\n",
    "\n",
    "Use algún método de selección de atributos para determinar un subconjunto de variables para explicar la variable <i> Permit slack </i> y justifique su elección de las variables a no considerar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfo_norm['permit slack'].describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfo_norm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposed_features = ['Permit Number', 'Permit Type', 'Permit Type Definition',\n",
    "       'Permit Creation Date', 'Block', 'Lot', 'Street Number', 'Street Name',\n",
    "       'Street Suffix', 'Description', 'Current Status', 'Current Status Date',\n",
    "       'Number of Existing Stories', 'Number of Proposed Stories',\n",
    "       'Fire Only Permit', 'Estimated Cost', 'Revised Cost', 'Existing Units',\n",
    "       'Proposed Units', 'Existing Construction Type', 'Zipcode', 'Record ID',\n",
    "       'days elapsed', 'permit duration']\n",
    "objective = ['permit slack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfo_norm.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sfo_norm['Street Suffix'].dtype == 'O':\n",
    "    print(\"holo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antes de seleccionar caracteristicas, se van a transformar las columnas de texto a enteros:\n",
    "import pandas as pd\n",
    "codes, uniques = [] , []\n",
    "for f in proposed_features:\n",
    "    if sfo_norm[f].dtype == 'O':\n",
    "        sfo_norm[f] = sfo_norm[f].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in proposed_features + objective:\n",
    "    sfo_norm[f].replace([np.inf, -np.inf], np.nan).dropna(inplace=True)\n",
    "# sfo_norm[proposed_features + objective].replace([np.inf, -np.inf], np.nan).dropna(inplace=True)\n",
    "\n",
    "#sfo_norm[proposed_features + objective]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = SelectKBest(mutual_info_classif, k = 5).fit_transform(sfo_norm[proposed_features], sfo_norm[objective])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
